"""
Twitter çˆ¬è™«æ¨¡å— - ä½¿ç”¨ requests ç›´æ¥çˆ¬å– Twitter å‰ç«¯
ä¸éœ€è¦ API Keyï¼Œç›´æ¥æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚
"""

import requests
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import re
import json
from urllib.parse import quote


class TwitterScraper:
    """Twitter çˆ¬è™«ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.session = requests.Session()
        # è®¾ç½® User-Agent æ¨¡æ‹Ÿæµè§ˆå™¨
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
        })

        # Twitter çš„ Guest Token è·å–
        self.guest_token = None
        self._get_guest_token()

    def _get_guest_token(self):
        """è·å– Twitter Guest Token"""
        try:
            response = self.session.post(
                'https://api.twitter.com/1.1/guest/activate.json',
                headers={
                    'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAANRILgAAAAAAnNwIzUejRCOuH5E6I8xnZz4puTs%3DZ1lq6wVV5Y7Rk5lQ7x5q5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y5Y'
                }
            )
            if response.status_code == 200:
                data = response.json()
                self.guest_token = data.get('guest_token')
                print(f"âœ… è·å– Guest Token æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  è·å– Guest Token å¤±è´¥: {e}")

    def get_user_tweets(self, username: str, hours_ago: int = 48, min_likes: int = 100) -> List[Dict]:
        """
        è·å–æŒ‡å®šç”¨æˆ·çš„æ¨æ–‡

        Args:
            username: Twitter ç”¨æˆ·å
            hours_ago: å¤šå°‘å°æ—¶å†…çš„æ¨æ–‡
            min_likes: æœ€å°ç‚¹èµæ•°

        Returns:
            æ¨æ–‡åˆ—è¡¨
        """
        if not self.guest_token:
            print("âš ï¸  æ—  Guest Tokenï¼Œè·³è¿‡")
            return []

        try:
            # æ„å»ºæŸ¥è¯¢ URL
            url = f"https://api.twitter.com/2/graphql/7wj Z1zO7zq-j-Z2j-Z1j-Z2j-Z1j-Z2j-Z1j-Z2j-Z1j-Z2j-Z1j-Z2j-Z1j-Z2j-Z1j-Z2j-Z1j-Z2j"

            # ä½¿ç”¨æ›´ç®€å•çš„æ–¹æ³•ï¼šç›´æ¥è¯·æ±‚ç”¨æˆ·ä¸»é¡µ
            user_url = f"https://twitter.com/{username}"
            response = self.session.get(user_url)

            if response.status_code == 200:
                # å°è¯•ä» HTML ä¸­æå–æ¨æ–‡æ•°æ®
                tweets = self._parse_tweets_from_html(response.text, username, hours_ago, min_likes)
                return tweets
            else:
                print(f"âš ï¸  è·å– @{username} ä¸»é¡µå¤±è´¥: {response.status_code}")
                return []

        except Exception as e:
            print(f"âš ï¸  è·å– @{username} æ¨æ–‡å‡ºé”™: {e}")
            return []

    def _parse_tweets_from_html(self, html: str, username: str, hours_ago: int, min_likes: int) -> List[Dict]:
        """
        ä» HTML ä¸­è§£ææ¨æ–‡æ•°æ®ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        """
        tweets = []

        try:
            # å°è¯•æ‰¾åˆ°åŒ…å«æ¨æ–‡æ•°æ®çš„ script æ ‡ç­¾
            pattern = r'"tweet":{"([^"]+)":"([^"]+)"'
            matches = re.findall(pattern, html)

            # è¿™ä¸ªè§£ææ¯”è¾ƒå¤æ‚ï¼Œæš‚æ—¶è¿”å›ç©ºåˆ—è¡¨
            # å®é™…ä¸Šéœ€è¦æ›´å¤æ‚çš„è§£æé€»è¾‘
            pass

        except Exception as e:
            pass

        return tweets


class TwitterNitterScraper:
    """ä½¿ç”¨ Nitter å®ä¾‹çš„çˆ¬è™«ï¼ˆæ›´ç®€å•ï¼‰"""

    def __init__(self, nitter_instance: str = "nitter.net"):
        """åˆå§‹åŒ– Nitter çˆ¬è™«"""
        self.base_url = f"https://{nitter_instance}"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })

    def get_user_tweets(self, username: str, hours_ago: int = 48, min_likes: int = 100) -> List[Dict]:
        """è·å–ç”¨æˆ·æ¨æ–‡"""
        try:
            url = f"{self.base_url}/{username}"
            response = self.session.get(url, timeout=10)

            if response.status_code != 200:
                print(f"âš ï¸  è·å– @{username} å¤±è´¥")
                return []

            # è§£æ HTML è·å–æ¨æ–‡
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(response.text, 'html.parser')

            tweets = []
            tweet_elements = soup.find_all('div', class_='timeline-item')

            for tweet_el in tweet_elements:
                try:
                    # æå–æ¨æ–‡å†…å®¹
                    text_el = tweet_el.find('div', class_='tweet-content')
                    if not text_el:
                        continue
                    text = text_el.get_text(strip=True)

                    # æå–ç‚¹èµæ•°
                    likes_el = tweet_el.find('span', class_='likes-count')
                    likes = int(likes_el.get_text()) if likes_el else 0

                    if likes < min_likes:
                        continue

                    # æå–æ—¶é—´
                    time_el = tweet_el.find('span', class_='tweet-time')
                    tweet_time = datetime.utcnow()  # é»˜è®¤å½“å‰æ—¶é—´

                    # æå–æ¨æ–‡é“¾æ¥
                    link_el = tweet_el.find('a', class_='tweet-link')
                    tweet_url = f"https://twitter.com/{username}/status/12345"  # å ä½

                    tweets.append({
                        'username': username,
                        'tweet_id': 'placeholder',
                        'text': text,
                        'created_at': tweet_time,
                        'like_count': likes,
                        'retweet_count': 0,
                        'reply_count': 0,
                        'quote_count': 0,
                        'impression_count': 0,
                        'url': tweet_url
                    })

                except Exception as e:
                    continue

            return tweets

        except Exception as e:
            print(f"âš ï¸  çˆ¬å– @{username} å‡ºé”™: {e}")
            return []


# ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®çš„ç®€åŒ–ç‰ˆæœ¬
class TwitterMockScraper:
    """æ¨¡æ‹Ÿæ•°æ®çˆ¬è™«ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""

    def __init__(self):
        """åˆå§‹åŒ–"""
        pass

    def get_user_tweets(self, username: str, hours_ago: int = 48, min_likes: int = 100) -> List[Dict]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ¨æ–‡æ•°æ®"""
        # æ¨¡æ‹Ÿä¸€äº›çƒ­é—¨æ¨æ–‡
        mock_tweets = [
            {
                'username': username,
                'tweet_id': f'{username}_001',
                'text': f'ğŸš€ Excited to announce our new AI model! This is a game changer for the industry. #AI #MachineLearning',
                'created_at': datetime.utcnow() - timedelta(hours=12),
                'like_count': 15234,
                'retweet_count': 3842,
                'reply_count': 892,
                'quote_count': 445,
                'impression_count': 1200000,
                'url': f'https://twitter.com/{username}/status/123456789'
            },
            {
                'username': username,
                'tweet_id': f'{username}_002',
                'text': f'Just published a paper on scaling laws for large language models. The results are fascinating! Link below ğŸ‘‡',
                'created_at': datetime.utcnow() - timedelta(hours=24),
                'like_count': 8756,
                'retweet_count': 2103,
                'reply_count': 456,
                'quote_count': 234,
                'impression_count': 560000,
                'url': f'https://twitter.com/{username}/status/123456790'
            }
        ]

        # åªè¿”å›ç¬¦åˆæ¡ä»¶çš„æ¨æ–‡
        return [t for t in mock_tweets if t['like_count'] >= min_likes]

    def sort_by_engagement(self, tweets: List[Dict]) -> List[Dict]:
        """æŒ‰äº’åŠ¨é‡æ’åºæ¨æ–‡"""
        def calculate_engagement(tweet):
            return (
                tweet['like_count'] * 1 +
                tweet['retweet_count'] * 2 +
                tweet['reply_count'] * 1.5 +
                tweet['quote_count'] * 1.5
            )

        sorted_tweets = sorted(tweets, key=calculate_engagement, reverse=True)
        return sorted_tweets
